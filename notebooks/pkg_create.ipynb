{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "df3cbe32-8f4b-4d91-a30c-51333d740415",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Package my_data_science_package structure created successfully.\n"
     ]
    }
   ],
   "source": [
    "# Create the package structure and write files\n",
    "\n",
    "import os\n",
    "\n",
    "# Define the package name\n",
    "package_name = \"my_data_science_package\"\n",
    "\n",
    "# Create directories for the package and tests\n",
    "os.makedirs(f\"{package_name}/\", exist_ok=True)\n",
    "os.makedirs(f\"tests/\", exist_ok=True)\n",
    "\n",
    "# Define module names and their content\n",
    "modules = {\n",
    "    \"data_processing.py\": \"\"\"\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.impute import KNNImputer\n",
    "from sklearn.experimental import enable_iterative_imputer\n",
    "from sklearn.impute import IterativeImputer\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "\n",
    "def summarize_dataframe(sdf):\n",
    "    \\\"\\\"\\\"\n",
    "    Summarizes the structure and content of a DataFrame.\n",
    "    \\\"\\\"\\\"\n",
    "    return pd.DataFrame({\n",
    "        'Column': sdf.columns,\n",
    "        'Non-Null Count': sdf.notnull().sum(),\n",
    "        'Data Type': sdf.dtypes,\n",
    "        'Unique Values': sdf.nunique(),\n",
    "        'Missing Values': sdf.isnull().sum(),\n",
    "        'Missing Values %': ((sdf.isnull().sum()*100)/len(sdf)).round(2)\n",
    "    }).reset_index(drop=True)\n",
    "\n",
    "def impute_missing_values(df):\n",
    "    \\\"\\\"\\\"\n",
    "    Imputes missing values using KNN and Iterative Imputer.\n",
    "    \\\"\\\"\\\"\n",
    "    df_imputed = df.copy()\n",
    "    categorical_columns = ['loan_request_reason', 'applicant_job_type']\n",
    "    label_encoders = {col: LabelEncoder() for col in categorical_columns}\n",
    "    for col, le in label_encoders.items():\n",
    "        df_imputed[col] = le.fit_transform(df_imputed[col].astype(str))\n",
    "    knn_imputer = KNNImputer(n_neighbors=5)\n",
    "    iterative_imputer = IterativeImputer(max_iter=10, random_state=42)\n",
    "    return df_imputed\n",
    "\"\"\",\n",
    "    \"data_visualization.py\": \"\"\"\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import pandas as pd\n",
    "\n",
    "def histogram_boxplot(data, feature, figsize=(12, 7), kde=True, bins=None):\n",
    "    \\\"\\\"\\\"\n",
    "    Boxplot and histogram combined for a feature.\n",
    "    \\\"\\\"\\\"\n",
    "    f, (ax_box, ax_hist) = plt.subplots(\n",
    "        nrows=2, sharex=True, gridspec_kw={\"height_ratios\": (0.25, 0.75)}, figsize=figsize\n",
    "    )\n",
    "    sns.boxplot(data=data, x=feature, ax=ax_box, showmeans=True, color=\"violet\")\n",
    "    sns.histplot(data=data, x=feature, kde=kde, ax=ax_hist, bins=bins, palette=\"winter\")\n",
    "    plt.show()\n",
    "\n",
    "def plot_correlation_heatmap(data, title):\n",
    "    \\\"\\\"\\\"\n",
    "    Plots a correlation heatmap of the dataset.\n",
    "    \\\"\\\"\\\"\n",
    "    plt.figure(figsize=(12, 10))\n",
    "    sns.heatmap(data.corr(), annot=True, fmt=\".2f\", cmap=\"coolwarm\")\n",
    "    plt.title(title, fontsize=16)\n",
    "    plt.show()\n",
    "\"\"\",\n",
    "    \"model_evaluation.py\": \"\"\"\n",
    "from sklearn.metrics import classification_report, confusion_matrix, accuracy_score, precision_score, recall_score\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import pandas as pd\n",
    "\n",
    "def metrics_score(actual, predicted):\n",
    "    \\\"\\\"\\\"\n",
    "    Calculates and displays classification metrics and confusion matrix.\n",
    "    \\\"\\\"\\\"\n",
    "    print(classification_report(actual, predicted))\n",
    "    cm = confusion_matrix(actual, predicted)\n",
    "    plt.figure(figsize=(8, 5))\n",
    "    sns.heatmap(cm, annot=True, fmt='.2f', xticklabels=['Not Converted', 'Converted'],\n",
    "                yticklabels=['Not Converted', 'Converted'])\n",
    "    plt.ylabel('Actual')\n",
    "    plt.xlabel('Predicted')\n",
    "    plt.show()\n",
    "\"\"\",\n",
    "    \"utils.py\": \"\"\"\n",
    "import pandas as pd\n",
    "\n",
    "def segregate_columns_by_dtype(df):\n",
    "    \\\"\\\"\\\"\n",
    "    Segregates DataFrame columns by their data types.\n",
    "    \\\"\\\"\\\"\n",
    "    return {dtype.name: df.select_dtypes(include=[dtype]).columns.tolist() for dtype in df.dtypes.unique()}\n",
    "\"\"\",\n",
    "}\n",
    "\n",
    "# Write the module files\n",
    "for module_name, content in modules.items():\n",
    "    with open(f\"{package_name}/{module_name}\", \"w\") as module_file:\n",
    "        module_file.write(content)\n",
    "\n",
    "# Create an empty __init__.py to make it a package\n",
    "with open(f\"{package_name}/__init__.py\", \"w\") as init_file:\n",
    "    init_file.write(\"\")\n",
    "\n",
    "# Write a basic setup.py\n",
    "setup_content = \"\"\"\n",
    "from setuptools import setup, find_packages\n",
    "\n",
    "setup(\n",
    "    name='my_data_science_package',\n",
    "    version='0.1.0',\n",
    "    description='A collection of data science tools.',\n",
    "    author='Your Name',\n",
    "    author_email='your.email@example.com',\n",
    "    packages=find_packages(),\n",
    "    install_requires=[\n",
    "        'pandas>=1.0',\n",
    "        'numpy>=1.20',\n",
    "        'matplotlib>=3.0',\n",
    "        'seaborn>=0.11',\n",
    "        'scikit-learn>=0.24',\n",
    "    ],\n",
    "    classifiers=[\n",
    "        'Programming Language :: Python :: 3',\n",
    "        'License :: OSI Approved :: MIT License',\n",
    "        'Operating System :: OS Independent',\n",
    "    ],\n",
    "    python_requires='>=3.7',\n",
    ")\n",
    "\"\"\"\n",
    "with open(\"setup.py\", \"w\") as setup_file:\n",
    "    setup_file.write(setup_content)\n",
    "\n",
    "# Write a README.md file\n",
    "with open(\"README.md\", \"w\") as readme_file:\n",
    "    readme_file.write(\"# My Data Science Package\\n\\nA collection of utilities for data science workflows.\")\n",
    "\n",
    "# Create placeholder test files\n",
    "test_files = [\n",
    "    \"test_data_processing.py\",\n",
    "    \"test_data_visualization.py\",\n",
    "    \"test_model_evaluation.py\",\n",
    "    \"test_utils.py\",\n",
    "]\n",
    "for test_file in test_files:\n",
    "    with open(f\"tests/{test_file}\", \"w\") as tf:\n",
    "        tf.write(\"# Write your tests here\\n\")\n",
    "\n",
    "print(f\"Package {package_name} structure created successfully.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "61d4e35d-d708-46e9-94b5-eb79c1381f5b",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.15"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
